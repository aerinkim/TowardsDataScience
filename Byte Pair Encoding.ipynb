{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Byte Pair Encoding (BPE) (Gage, 1994) is a simple data compression technique that iteratively replaces the most frequent pair of bytes in a sequence with a single, unused byte. We adapt this algorithm for word segmentation. Instead of merging frequent pairs of bytes, we merge characters or character sequences.\n",
    "\n",
    "Algorithm: \n",
    "\n",
    "1. Initialize the symbol vocabulary with the character vocabulary, and represent each word as a sequence of characters, plus a special end-of-word symbol ‘<\\w>’, which allows us to restore the original tokenization after translation.\n",
    "2. Iteratively count all symbol pairs and replace each occurrence of the most frequent pair (‘A’, ‘B’) with a new symbol ‘AB’.\n",
    "3. Each merge operation produces a new symbol which represents a character n-gram. Frequent character n-grams (or whole words) are eventually merged into a single symbol, thus BPE requires no shortlist.\n",
    "4. The final symbol vocabulary size is equal to the size of the initial vocabulary, plus the number of merge operations – the latter is the only hyperparameter of the algorithm.\n",
    "\n",
    "In practice, we increase efficiency by indexing all pairs, and updating data structures incrementally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "        \"l o w </w>\": 5,\n",
    "        \"l o w e r </w>\": 2,\n",
    "        \"w i d e s t </w>\": 3,\n",
    "        \"n e w e s t </w>\": 6\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stats(vocab):\n",
    "    pairs = collections.defaultdict(int)\n",
    "    for word, freq in vocab.items():\n",
    "        symbols = word.split()\n",
    "        #print(\"symbols:\", symbols)\n",
    "        for i in range(len(symbols)-1):\n",
    "            pairs[symbols[i],symbols[i+1]] += freq\n",
    "            #print(pairs)\n",
    "        #print(\"\\n\")\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {('d', 'e'): 3,\n",
       "             ('e', 'r'): 2,\n",
       "             ('e', 's'): 9,\n",
       "             ('e', 'w'): 6,\n",
       "             ('i', 'd'): 3,\n",
       "             ('l', 'o'): 7,\n",
       "             ('n', 'e'): 6,\n",
       "             ('o', 'w'): 7,\n",
       "             ('r', '</w>'): 2,\n",
       "             ('s', 't'): 9,\n",
       "             ('t', '</w>'): 9,\n",
       "             ('w', '</w>'): 5,\n",
       "             ('w', 'e'): 8,\n",
       "             ('w', 'i'): 3})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stats(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The maximum length of pair is 2 because we used .split() which splits words into characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_vocab(pair, v_in):\n",
    "    v_out = {}\n",
    "    bigram_pattern = re.escape(' '.join(pair))\n",
    "    p = re.compile(r'(?<!\\S)' + bigram_pattern + r'(?!\\S)')\n",
    "    for word in v_in:\n",
    "        w_out = p.sub(''.join(pair), word)\n",
    "        v_out[w_out] = v_in[word]\n",
    "    return v_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = get_stats(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {('d', 'e'): 3,\n",
       "             ('e', 'r'): 2,\n",
       "             ('e', 's'): 9,\n",
       "             ('e', 'w'): 6,\n",
       "             ('i', 'd'): 3,\n",
       "             ('l', 'o'): 7,\n",
       "             ('n', 'e'): 6,\n",
       "             ('o', 'w'): 7,\n",
       "             ('r', '</w>'): 2,\n",
       "             ('s', 't'): 9,\n",
       "             ('t', '</w>'): 9,\n",
       "             ('w', '</w>'): 5,\n",
       "             ('w', 'e'): 8,\n",
       "             ('w', 'i'): 3})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best = max(pairs, key=pairs.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('e', 's')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = merge_vocab(best, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l o w </w>': 5, 'l o w e r </w>': 2, 'w i d es t </w>': 3, 'n e w es t </w>': 6}\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l o w </w>': 5, 'l o w e r </w>': 2, 'w i d es t </w>': 3, 'n e w es t </w>': 6}\n",
      "{'l o w </w>': 5, 'l o w e r </w>': 2, 'w i d est </w>': 3, 'n e w est </w>': 6}\n",
      "{'l o w </w>': 5, 'l o w e r </w>': 2, 'w i d est</w>': 3, 'n e w est</w>': 6}\n",
      "{'lo w </w>': 5, 'lo w e r </w>': 2, 'w i d est</w>': 3, 'n e w est</w>': 6}\n",
      "{'low </w>': 5, 'low e r </w>': 2, 'w i d est</w>': 3, 'n e w est</w>': 6}\n",
      "{'low </w>': 5, 'low e r </w>': 2, 'w i d est</w>': 3, 'ne w est</w>': 6}\n",
      "{'low </w>': 5, 'low e r </w>': 2, 'w i d est</w>': 3, 'new est</w>': 6}\n",
      "{'low </w>': 5, 'low e r </w>': 2, 'w i d est</w>': 3, 'newest</w>': 6}\n",
      "{'low</w>': 5, 'low e r </w>': 2, 'w i d est</w>': 3, 'newest</w>': 6}\n",
      "{'low</w>': 5, 'low e r </w>': 2, 'wi d est</w>': 3, 'newest</w>': 6}\n",
      "{'low</w>': 5, 'low e r </w>': 2, 'wid est</w>': 3, 'newest</w>': 6}\n",
      "{'low</w>': 5, 'low e r </w>': 2, 'widest</w>': 3, 'newest</w>': 6}\n",
      "{'low</w>': 5, 'lowe r </w>': 2, 'widest</w>': 3, 'newest</w>': 6}\n",
      "{'low</w>': 5, 'lower </w>': 2, 'widest</w>': 3, 'newest</w>': 6}\n",
      "{'low</w>': 5, 'lower</w>': 2, 'widest</w>': 3, 'newest</w>': 6}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-e915b671d8f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_merges\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mpairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpairs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mvocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerge_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "num_merges = 20\n",
    "for i in range(num_merges):\n",
    "    pairs = get_stats(vocab)\n",
    "    best = max(pairs, key=pairs.get)\n",
    "    vocab = merge_vocab(best, vocab)\n",
    "    print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The final symbol vocabulary size is equal to the size of the initial vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
